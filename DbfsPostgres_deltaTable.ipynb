{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"92c5639a-b3f1-4acb-b157-e13375cda59c","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import udf,col\n","from pyspark.sql.types import StructType, StructField, StringType\n","import os\n","import psycopg2\n","\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Create delta tables\") \\\n","        .getOrCreate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"12447f41-a19d-40fe-b98e-fe1ff691ec9e","showTitle":false,"title":""}},"outputs":[],"source":["# Use the database demodb in the catalog hive_metastore\n","spark.sql(\"USE DATABASE demodb;\")\n","\n","# Queries to get data from the postgres database\n","queries = [\n","    {\n","        \"table\":\"airports_data\",\n","        \"query\":\"SELECT a.airport_code, a.airport_name, a.city, a.coordinates FROM public.airports_data a LIMIT 200\",\n","        \"columns\":[\"airport_code\", \"airport_name\", \"city\", \"coordinates\"] \n","        }\n","    ,{   \"table\":\"aircrafts_data\", \n","        \"query\":\" SELECT b.aircraft_code, b.model, b.range FROM public.aircrafts_data b LIMIT 200\",\n","        \"columns\":[ \"aircraft_code\", \"model\",\"range\"] \n","        } \n","    ]\n","\n","def query_database(query):\n","    \"\"\"Get data from postgres database on the database hosting server.\n","    Args:\n","        query(Str): The query for getting data from postgres database.\n","    return: \n","        my_cursor(cursor):Returns data.\n","    \"\"\"\n","    my_connection = psycopg2.connect(user=\"******\", password=\"*****\", host=\"******\",port=\"5432\",database=\"******\")\n","    my_cursor = my_connection.cursor()\n","    my_cursor.execute(query)\n","    return my_cursor.fetchall()\n","\n","def data_postgres_database_to_delta_table():\n","    \"\"\"Get data from the postgres database, and save as delta table.\n","    Args:\n","        table_name(Str): The table name which contains data.\n","        columns(list): List of columns name of the table.\n","    \"\"\"\n","    for t in queries:\n","        df = spark.createDataFrame(query_database(t[\"query\"])).toDF(*t[\"columns\"])\n","        df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(t[\"table\"])\n","    \n","def dbfs_to_delta_table(path_dbfs):\n","    \"\"\"Get data from DBFS.\n","    Args:\n","        path_dbfs(Str): The path where csv file are on Databrick File System\n","    \"\"\"\n","    list_of_csv_file = os.listdir(path_dbfs)\n","    location = path_dbfs.replace(\"/dbfs\",\"\")\n","    for file in list_of_csv_file:\n","        drop_table = \"DROP TABLE IF EXISTS \" + file\n","        spark.sql(drop_table)\n","        df = spark.read.format(\"csv\") \\\n","            .option(\"inferSchema\", \"true\") \\\n","            .option(\"header\", \"true\") \\\n","            .option(\"sep\",\",\") \\\n","            .load(location + \"/\" + file)\n","        df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(file[:file.index(\".\")])\n","    \n","data_postgres_database_to_delta_table()\n","dbfs_to_delta_table(\"/dbfs/data_of_demodb\")\n","\n","\n"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":-1,"dataframes":["_sqldf"]},"pythonIndentUnit":4},"notebookName":"load_data_to_s3","notebookOrigID":2288822831207585,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
